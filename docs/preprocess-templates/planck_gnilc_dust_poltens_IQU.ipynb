{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySM 3 dust templates based on Planck GNILC maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to pre-process galactic dust maps from the [Planck analysis with GNILC](https://arxiv.org/abs/1605.09387)\n",
    "to create a dust model for PySM 3 which is based on real data at large scale and has added gaussian fluctuations at small scales.\n",
    "\n",
    "These dust maps, compared to the commander results used by the `d1` model of PySM 2, have the CIB signal removed and less noise.\n",
    "This notebook focuses only on the IQU templates at 353 GHz, \"dust temperature\" and \"dust spectral index\" will be processed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"64\" # for jupyter.nersc.gov otherwise the notebook only uses 2 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysm3 as pysm\n",
    "import pysm3.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 2048\n",
    "degraded_nside = 2048 # to speedup notebook for testing\n",
    "lmax = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp = \"I\"\n",
    "comp = \"IQU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = list(enumerate(comp))\n",
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_components = [\"II\", \"EE\", \"BB\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masks\n",
    "\n",
    "Using the Planck Common mask for polarization from the 3rd release:\n",
    "\n",
    "https://irsa.ipac.caltech.edu/data/Planck/release_3/ancillary-data/previews/COM_Mask_CMB-common-Mask-Pol_2048_R3.00/index.html\n",
    "\n",
    "and also the one for temperature and create a union mask of the 2, as we will be processing both polarization and intensity together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planck_mask_filename_QU = \"COM_Mask_CMB-common-Mask-Pol_2048_R3.00.fits\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planck_mask_filename_I = \"COM_Mask_CMB-common-Mask-Int_2048_R3.00.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planck_mask_filenames= [planck_mask_filename_QU, planck_mask_filename_I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for planck_mask_filename in [planck_mask_filename_QU, planck_mask_filename_I]:\n",
    "    if not os.path.exists(os.path.join(\"data\", planck_mask_filename)):\n",
    "        !wget -O data/$planck_mask_filename https://irsa.ipac.caltech.edu/data/Planck/release_3/ancillary-data/masks/$planck_mask_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.open(\"data/\" + planck_mask_filename_QU)[1].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planck_mask = np.logical_and(*[hp.read_map(os.path.join(\"data\", planck_mask_filename)) for  planck_mask_filename in planck_mask_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(planck_mask) # no apodization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(planck_mask, title=f\"Planck common galactic mask, {comp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planck GNILC dust\n",
    "\n",
    "Downloaded from the Planck Legacy Archive (PLA), the [GNILC templates](https://wiki.cosmos.esa.int/planck-legacy-archive/index.php/Foreground_maps#GNILC_thermal_dust_maps) are available either at a single resolution of 80 arcminutes or at variable resolution, where regions of higher emission have 5 arcmin resolution. Here we want to fit the slope of the small scales therefore we want the variable resolution image which has the least smoothing applied.\n",
    "\n",
    "Rename `varres` to `unires` in the filename to use the 80 arcmin uniform resolution map instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_map_filename = \"COM_CompMap_IQU-thermaldust-gnilc-varres_2048_R3.00.fits\"\n",
    "dust_map_path = os.path.join(\"data\", dust_map_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dust_map_path):\n",
    "    !wget -O $dust_map_path http://pla.esac.esa.int/pla/aio/product-action?MAP.MAP_ID=$dust_map_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dust_map_R2_filename = \"COM_CompMap_Dust-GNILC-F353_2048_R2.00.fits\"\n",
    "# dust_map_R2_path = os.path.join(\"data\", dust_map_R2_filename)\n",
    "# if \"varres\" in dust_map_filename:\n",
    "#    if not os.path.exists(dust_map_R2_path):\n",
    "#        !wget -O $dust_map_R2_path http://pla.esac.esa.int/pla/aio/product-action?MAP.MAP_ID=$dust_map_R2_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.open(dust_map_path).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck,h = hp.read_map(dust_map_path, [c+\"_STOKES\" for c in comp], h=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if degraded_nside != nside:\n",
    "    m_planck = hp.ud_grade(m_planck, degraded_nside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input units are $K_{CMB}$, PySM templates use $\\mu K_{RJ}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck <<= u.K_CMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck = m_planck.to(\"uK_RJ\", equivalencies=u.cmb_equivalencies(353*u.GHz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if m_planck.ndim == 1:\n",
    "    m_planck = m_planck.reshape((1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_pol, pol in components:\n",
    "    hp.mollview(m_planck[i_pol], title=\"Planck-GNILC dust \" + pol, unit=m_planck.unit, min=-300, max=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the log of the polarization tensor\n",
    "\n",
    "I - PxP and polarization fraction\n",
    "\n",
    "  $\n",
    "    \\left[ \\begin{array}{cc} i+q & u \\\\ u & i-q \\end{array} \\right] \\ = \\\n",
    "    \\ln \\left[ \\begin{array}{cc} I+Q & U \\\\ U & I-Q \\end{array} \\right]\n",
    "  $\n",
    "\n",
    "\n",
    "$\n",
    "    i = \\frac{1}{2}\\, \\ln \\left(I^2-P^2\\right), \\hspace{1em}\n",
    "    q = \\frac{1}{2}\\, \\frac{Q}{P}\\, \\ln \\frac{I+P}{I-P}, \\hspace{1em}\n",
    "    u = \\frac{1}{2}\\, \\frac{U}{P}\\, \\ln \\frac{I+P}{I-P}\n",
    "$\n",
    "\n",
    "$    I = e^{i} \\cosh p, \\hspace{2em}\n",
    "    Q = \\frac{q}{p} e^{i} \\sinh p, \\hspace{2em}\n",
    "    U = \\frac{u}{p} e^{i} \\sinh p\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_log_pol_tens(m):\n",
    "    P = np.sqrt(m[1]**2 + m[2]**2)\n",
    "    log_pol_tens = np.empty_like(m)\n",
    "    log_pol_tens[0] = np.log(m[0]**2 - P**2)/2.0\n",
    "    log_pol_tens[1:] = m[1:]/P * np.log((m[0]+P)/(m[0]-P))/2.0\n",
    "    return log_pol_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_pol_tens_to_map(log_pol_tens):\n",
    "    P = np.sqrt(log_pol_tens[1]**2 + log_pol_tens[2]**2)\n",
    "    m = np.empty_like(log_pol_tens)\n",
    "    m[0] = np.exp(log_pol_tens[0]) * np.cosh(P)\n",
    "    m[1:] = log_pol_tens[1:]/P * np.exp(log_pol_tens[0]) * np.sinh(P)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pol_tens = map_to_log_pol_tens(m_planck.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_back = log_pol_tens_to_map(log_pol_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_back - m_planck.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview((m_back - m_planck.value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del m_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(log_pol_tens[0], title=\"Log pol tensor I\", max=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(log_pol_tens[1], title=\"Log pol tensor Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(log_pol_tens[2], title=\"Log pol tensor U\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular power spectrum with `namaster`\n",
    "\n",
    "We use `namaster` to estimate the power spectrum of the masked map,\n",
    "compared to `anafast`, `namaster` properly deconvolves the mask to remove the\n",
    "correlations between different $C_\\ell$ caused by the mask.\n",
    "\n",
    "We don't need to deconvolve the beam, we won't be using the values at high $\\ell$ anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymaster as nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_2 = nmt.NmtField(planck_mask, log_pol_tens[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning = nmt.NmtBin(nside=degraded_nside, nlb=1, lmax=lmax, is_Dell=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_namaster = nmt.compute_full_master(f_2, f_2, binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = {}\n",
    "cl[\"EE\"] = np.concatenate([[0,0], cl_namaster[0]])\n",
    "cl[\"BB\"] = np.concatenate([[0,0], cl_namaster[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.write_cl(f\"data/cl_gnilc_log_pol_tens_pol.fits\", cl_namaster, overwrite=True)\n",
    "# cl_namaster = hp.read_cl(\"cl_gnilc_varres.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_0 = nmt.NmtField(planck_mask, log_pol_tens[:1])\n",
    "cl_namaster_I = nmt.compute_full_master(f_0, f_0, binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.write_cl(f\"data/cl_gnilc_log_pol_tens_temp.fits\", cl_namaster_I, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl[\"II\"] = np.concatenate([[0,0], cl_namaster_I[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell = np.concatenate([[0,1], binning.get_effective_ells()])\n",
    "cl_norm = ell*(ell+1)/np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_norm[0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maps are smoothed (with different beams in different regions), so we try to select the region of $\\ell$ which is roughtly linear in `loglog` scale just before the curvature of the smoothing looks to start dominating. We will use this region to fit to extrapolate small scale power to high $\\ell$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell_fit_low = 100\n",
    "ell_fit_high = 300\n",
    "ell_star = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_fwhm = 60 * u.arcmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ell = hp.gauss_beam(fwhm=map_fwhm.to_value(u.radian), lmax=lmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in [100, 200, 300, 400, 500]:\n",
    "    print(e, w_ell[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w_ell)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"II\"]:\n",
    "    plt.semilogx(cl_norm * cl[c], label=f\"NaMaster {c} $C_\\ell$\")\n",
    "    #plt.plot(cl_norm * cl[c] / w_ell**2, label=f\"NaMaster {c} $C_\\ell$\")\n",
    "    plt.plot(np.log(w_ell**2),  label=f\"Beam {c} $C_\\ell$\")\n",
    "plt.axvline(ell_fit_low, linestyle=\"--\", color=\"black\", label=\"$ \\ell={} $\".format(ell_fit_low))\n",
    "plt.axvline(ell_fit_high, linestyle=\"--\", color=\"gray\", label=\"$ \\ell={} $\".format(ell_fit_high))\n",
    "plt.legend()\n",
    "plt.ylabel(\"$\\ell(\\ell+1)C_\\ell/2\\pi [\\mu K_{RJ}]$\")\n",
    "plt.xlabel((\"$\\ell$\"))\n",
    "#plt.ylim(1e-2, 1e2)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(ell, A, gamma):\n",
    "    return A + np.log(ell) * gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.arange(ell_fit_low, ell_fit_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_fit, gamma_fit, A_fit_std, gamma_fit_std = {},{},{},{}\n",
    "for pol in spectra_components:\n",
    "    ydata = xdata*(xdata+1)/np.pi/2 * cl[pol][xdata]\n",
    "    (A_fit[pol], gamma_fit[pol]), cov = curve_fit(model, xdata, ydata)\n",
    "\n",
    "    A_fit_std[pol], gamma_fit_std[pol] = np.sqrt(np.diag(cov))\n",
    "    plt.figure()\n",
    "    plt.semilogx(ell, ell*(ell+1)/np.pi/2 * cl[pol], label=\"NaMaster $C_\\ell$\")\n",
    "    plt.semilogx(ell, ell*(ell+1)/np.pi/2 * cl[pol], label=\"NaMaster $C_\\ell smoothed$\")\n",
    "    # plt.loglog(ell, ell*(ell+1)/np.pi/2 * cl_sigma_G[pol], label=\"SS $C_\\ell$\")\n",
    "\n",
    "    plt.plot(ell, model(ell, A_fit[pol], gamma_fit[pol]), label=\"model fit\")\n",
    "    plt.axvline(ell_fit_low, linestyle=\"--\", color=\"black\", label=\"$ \\ell={} $\".format(ell_fit_low))\n",
    "    plt.axvline(ell_fit_high, linestyle=\"--\", color=\"gray\", label=\"$ \\ell={} $\".format(ell_fit_high))\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.title(f\"{pol} power spectrum for dust\")\n",
    "    plt.ylabel(\"$\\ell(\\ell+1)C_\\ell/2\\pi [\\mu K_{RJ}]$\")\n",
    "    plt.xlabel((\"$\\ell$\"))\n",
    "    #plt.xlim(0, 400)\n",
    "    #plt.ylim(1, 30);\n",
    "    plt.xlim(ell_fit_low*.7, lmax)\n",
    "    plt.ylim(0, 0.5 if pol == \"II\" else 2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_fit, A_fit_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_fit, gamma_fit_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the smoothed GNILC map\n",
    "\n",
    "Now that we have fitted the small scales behaviour on the GNILC map at higher resolution, we load the GNILC smoothed map,\n",
    "at 80 arcminutes and fill in the small scale fluctiaitons on that map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_map_smoothed_filename = \"COM_CompMap_IQU-thermaldust-gnilc-unires_2048_R3.00.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dust_map_smoothed_filename):\n",
    "    !wget -O $dust_map_filename http://pla.esac.esa.int/pla/aio/product-action?MAP.MAP_ID=$dust_map_smoothed_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck_smoothed = hp.read_map(dust_map_smoothed_filename, (0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if comp == \"I\":\n",
    "    m_planck_smoothed = m_planck_smoothed[:1]\n",
    "else:\n",
    "    m_planck_smoothed[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck_smoothed <<= u.K_CMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck_smoothed = m_planck_smoothed.to(\"uK_RJ\", equivalencies=u.cmb_equivalencies(353*u.GHz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(m_planck_smoothed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window function\n",
    "\n",
    "The window function is used to smooth the input templates to remove the high $\\ell$ noise and its inverse is used for the added small scales.\n",
    "\n",
    "In the PySM 2 paper, smoothing was at 2.6 degrees. Here we just use the GNILC map at uniform resolution of 80 arcminutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_fwhm_deg = 80/60 # 80 arcmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_fwhm_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "180/theta_fwhm_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_fwhm = np.radians(theta_fwhm_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ell = hp.gauss_beam(fwhm=theta_fwhm, lmax=5*lmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_w_ell = 1 - w_ell**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(w_ell**2)\n",
    "plt.loglog(inv_w_ell)\n",
    "plt.axvline(180/theta_fwhm_deg, color=\"black\", linestyle=\"--\")\n",
    "plt.grid()\n",
    "plt.xlim([1,1000])\n",
    "plt.ylim([1e-2, 1e2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate a realization of small scales fluctuations\n",
    "\n",
    "We simulate small scales fluctuations using the inverse of the window function and the fitted amplitude and slope.\n",
    "Also fix the seed to make this reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777 * len(comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros(len(ell), dtype=np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if comp == \"I\":\n",
    "    cl_in = A_fit[\"II\"] * ell**gamma_fit[\"II\"] * inv_w_ell / cl_norm\n",
    "    cl_in[0] = 0\n",
    "    m_sigma_G = hp.synfast(\n",
    "    cl_in, nside, new=True)\n",
    "    del cl_in\n",
    "else:\n",
    "    cl_EE = A_fit[\"EE\"] * ell**gamma_fit[\"EE\"] * inv_w_ell / cl_norm\n",
    "    cl_EE[0] = 0\n",
    "    cl_BB = A_fit[\"BB\"] * ell**gamma_fit[\"BB\"] * inv_w_ell / cl_norm\n",
    "    cl_BB[0]=0\n",
    "    m_sigma_G = hp.synfast([\n",
    "    zeros,\n",
    "    cl_EE,\n",
    "    cl_BB,\n",
    "    zeros, zeros, zeros], nside, new=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not np.any(np.isnan(m_sigma_G)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write output map\n",
    "\n",
    "We write the output map, GNILC smoothed at 80 arcmin + the small scale fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_total = m_planck_smoothed.value + m_sigma_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.write_map(f\"gnilc_plus_smallscales_{comp}.fits\", m_total, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the small scale fluctuations with large scale amplitude\n",
    "\n",
    "As described in the PySM 2 paper, we compute the power spectrum in every patch e.g. pixel at $N_{side}=2$, and then scale the small scale fluctuations so that they agree with the power at large scale (we use a specific $\\ell$ to make the comparison, in the paper it is 69, here we are doing less smoothing so we use a higher ell, see `ell_star`.\n",
    "\n",
    "This process doesn't have a large impact on the output spectra, the idea is that in each $N_{side}=2$ pixel we want to scale the gaussian fluctuations so that they are consistent with the power at low ell.\n",
    "So we will have higher gaussian fluctuations on the galaxy where there is stronger dust emission.\n",
    "\n",
    "$$\n",
    "N(\\boldsymbol{\\hat{n}}) = \\sqrt{\\dfrac{C_{\\ell_*}(\\boldsymbol{\\hat{n}})}{A\\ell_*^\\gamma}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_indices = hp.ud_grade(np.arange(hp.nside2npix(2)), nside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(patch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside_patches = 2\n",
    "n_patches = hp.nside2npix(nside_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_pols = [1,2] if comp == \"QU\" else [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pols = list(zip(spectra_components, i_pols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = {i_pol:np.zeros(n_patches, dtype=np.double) for i_pol in i_pols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_patch in range(n_patches):\n",
    "    print(i_patch)\n",
    "    m_patch = np.zeros_like(m_planck_smoothed)\n",
    "    m_patch[:, patch_indices == i_patch] = m_planck_smoothed[:, patch_indices == i_patch]\n",
    "    # m_patch = hp.smoothing(m_patch[0], fwhm=np.radians(10), lmax=2*ell_star)\n",
    "    cl_patch = hp.anafast(m_patch, lmax=2*ell_star, use_pixel_weights=True)\n",
    "    if cl_patch.ndim == 1:\n",
    "        cl_patch = cl_patch.reshape((1,-1))\n",
    "    for pol,i_pol in pols:\n",
    "        N[i_pol][i_patch] = np.sqrt(cl_patch[i_pol][ell_star] / n_patches / (A_fit[pol] * ell_star ** gamma_fit[pol]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in N.items():\n",
    "    hp.mollview(v, title=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_zeros = np.zeros(hp.nside2npix(nside), dtype=np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_N = [N[0]] if comp == \"I\" else [np.zeros(len(N[1])), N[1], N[2]]\n",
    "hp.write_map(f\"N_{comp}.fits\", m_N, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = hp.read_map(\"N.fits\", (0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_smoothed = hp.smoothing(hp.ud_grade(m_N[0], nside) if comp==\"I\" else hp.ud_grade(m_N, nside), lmax=lmax, fwhm=np.radians(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N_smoothed.ndim == 1:\n",
    "    N_smoothed = N_smoothed.reshape((1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.write_map(f\"N_smoothed_{comp}.fits\", N_smoothed, overwrite=True)\n",
    "# N_smoothed = hp.read_map(\"N_smoothed.fits\", (0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_pol in i_pols:\n",
    "    N_smoothed[i_pol] /= (N_smoothed[i_pol]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.write_map(f\"N_smoothed_normalized_{comp}.fits\", N_smoothed, overwrite=True)\n",
    "# N_smoothed = hp.read_map(\"N_smoothed.fits\", (0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_pol, pol in enumerate(\"IQU\"):\n",
    "    hp.mollview(N_smoothed[i_pol,:], title=pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_total = m_planck_smoothed.value + m_sigma_G * N_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.write_map(f\"gnilc_plus_smallscales_scaled_{comp}.fits\", m_total, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "namaster",
   "language": "python",
   "name": "namaster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
