{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySM 3 dust templates based on Planck GNILC maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to pre-process galactic dust maps from the [Planck analysis with GNILC](https://arxiv.org/abs/1605.09387)\n",
    "to create a dust model for PySM 3 which is based on real data at large scale and has added gaussian fluctuations at small scales.\n",
    "\n",
    "These dust maps, compared to the commander results used by the `d1` model of PySM 2, have the CIB signal removed and less noise.\n",
    "This notebook focuses only on the IQU templates at 353 GHz, \"dust temperature\" and \"dust spectral index\" will be processed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"64\" # for jupyter.nersc.gov otherwise the notebook only uses 2 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymaster as nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysm3 as pysm\n",
    "import pysm3.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 2048\n",
    "lmax = nside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = \"IQU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = list(enumerate(comp))\n",
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_components = [\"TT\", \"EE\", \"BB\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planck_mask = hp.reorder(\n",
    "    fits.open(\"data/HFI_Mask_GalPlane-apo2_2048_R2.00.fits\")[1].data[\"GAL080\"], n2r=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(planck_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planck GNILC dust\n",
    "\n",
    "Downloaded from the Planck Legacy Archive (PLA), the [GNILC templates](https://wiki.cosmos.esa.int/planck-legacy-archive/index.php/Foreground_maps#GNILC_thermal_dust_maps) are available either at a single resolution of 80 arcminutes or at variable resolution, where regions of higher emission have 5 arcmin resolution. Here we want to fit the slope of the small scales therefore we want the variable resolution image which has the least smoothing applied.\n",
    "\n",
    "Rename `varres` to `unires` in the filename to use the 80 arcmin uniform resolution map instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_map_filename = \"COM_CompMap_IQU-thermaldust-gnilc-varres_2048_R3.00.fits\"\n",
    "dust_map_path = os.path.join(\"data\", dust_map_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dust_map_path):\n",
    "    !wget -O $dust_map_path http://pla.esac.esa.int/pla/aio/product-action?MAP.MAP_ID=$dust_map_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.open(dust_map_path).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.open(dust_map_path)[1].data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = hp.read_map(dust_map_path, [\"II_COV\", \"QQ_COV\", \"UU_COV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_weights = 1/cov[0]/1e11*planck_mask\n",
    "P_weights = 2/(cov[1]+cov[2])/1e11*planck_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(I_weights, title=\"II inverse noise weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(P_weights, title=\"P inverse noise weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck,h = hp.read_map(dust_map_path, [c+\"_STOKES\" for c in comp], h=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input units are $K_{CMB}$, PySM templates use $\\mu K_{RJ}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck <<= u.K_CMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck = m_planck.to(\"uK_RJ\", equivalencies=u.cmb_equivalencies(353*u.GHz)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if m_planck.ndim == 1:\n",
    "    m_planck = m_planck.reshape((1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck[0] = (hp.read_map(\"data/COM_CompMap_Dust-GNILC-F353_2048_R2.00.fits\") * u.MJy/u.sr).to(\n",
    "    \"uK_RJ\", equivalencies=u.cmb_equivalencies(353*u.GHz)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.isinf(m_planck[0])).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove CIB monopole\n",
    "\n",
    "Based on Section 2.2 of [Planck 2018: XII](https://arxiv.org/pdf/1807.06212.pdf), the contributions to the monopole in the 353 GHz GNILC intensity map are CIB and dust. They do not remove the CIB contribution, and apply some process to improve on the estimate of the dust monopole the maps already contained.\n",
    "\n",
    "The numbers for each contribution can be found in Table 12 of [Planck 2018: III](https://arxiv.org/abs/1807.06207), which I've pasted below. This seems to indicate there is a relevant (but very small) contribution from zodiacal emission as well, which is not discussed in XII.\n",
    "\n",
    "The simplest first thing to do is just remove the CIB contribution, for which I've been using the number in Table 12: 0.13 MJy/sr at 353 GHz. Perhaps we also need to remove zodiacal emission, and perhaps we also need to refine the dust monopole model as was done in XII.   \n",
    "\n",
    "![Screen Shot 2021-04-26 at 10 27 15 AM](https://user-images.githubusercontent.com/16899444/116125124-f9f88700-a679-11eb-80d3-d90c0d559ee9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIB_monopole = u.Quantity(\"0.13 MJy/sr\").to(u.uK_RJ, equivalencies=u.cmb_equivalencies(353*u.GHz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIB_monopole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck[0] -= CIB_monopole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_planck[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_pol, pol in components:\n",
    "    hp.mollview(m_planck[i_pol], title=\"Planck-GNILC dust \" + pol, unit=m_planck.unit, min=-300, max=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the log of the polarization tensor\n",
    "\n",
    "I - PxP and polarization fraction\n",
    "\n",
    "  $\n",
    "    \\left[ \\begin{array}{cc} i+q & u \\\\ u & i-q \\end{array} \\right] \\ = \\\n",
    "    \\ln \\left[ \\begin{array}{cc} I+Q & U \\\\ U & I-Q \\end{array} \\right]\n",
    "  $\n",
    "\n",
    "\n",
    "$\n",
    "    i = \\frac{1}{2}\\, \\ln \\left(I^2-P^2\\right), \\hspace{1em}\n",
    "    q = \\frac{1}{2}\\, \\frac{Q}{P}\\, \\ln \\frac{I+P}{I-P}, \\hspace{1em}\n",
    "    u = \\frac{1}{2}\\, \\frac{U}{P}\\, \\ln \\frac{I+P}{I-P}\n",
    "$\n",
    "\n",
    "$    I = e^{i} \\cosh p, \\hspace{2em}\n",
    "    Q = \\frac{q}{p} e^{i} \\sinh p, \\hspace{2em}\n",
    "    U = \\frac{u}{p} e^{i} \\sinh p\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from log_pol_tens_utils import map_to_log_pol_tens, log_pol_tens_to_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pol_tens = map_to_log_pol_tens(m_planck.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_back = log_pol_tens_to_map(log_pol_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_back - m_planck.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview((m_back - m_planck.value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del m_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    log_pol_tens[i, np.isnan(log_pol_tens[i])] = np.nanmedian(log_pol_tens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isnan(log_pol_tens).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(log_pol_tens[0], title=\"Log pol tensor I\", max=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pol_tens = hp.ma(log_pol_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pol_tens.mask = planck_mask < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(hp.fit_dipole(log_pol_tens[0])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono, dip_vector = hp.fit_dipole(log_pol_tens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dip_inplace(m, dip_vector):\n",
    "    npix = m.shape[-1]\n",
    "    nside = hp.npix2nside(npix)\n",
    "    m.data[:] -= np.dot(dip_vector, hp.pix2vec(nside, np.arange(npix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing monopole and dipole to avoid issues in taking the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dip_inplace(log_pol_tens.data[0], dip_vector)\n",
    "log_pol_tens[0].data[:] -= mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pol_tens[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(log_pol_tens[0], title=\"Log pol tensor I\", min=-2, max=2, xsize=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(log_pol_tens.data[0], title=\"Log pol tensor I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(log_pol_tens[1], title=\"Log pol tensor Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(log_pol_tens[2], title=\"Log pol tensor U\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular power spectrum with `namaster`\n",
    "\n",
    "We use `namaster` to estimate the power spectrum of the masked map,\n",
    "compared to `anafast`, `namaster` properly deconvolves the mask to remove the\n",
    "correlations between different $C_\\ell$ caused by the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_pol_tens[0] *= I_weights\n",
    "# log_pol_tens[1:] *= P_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import run_namaster\n",
    "ell, cl_norm, cl = run_namaster(log_pol_tens.data, planck_mask, lmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cl[\"TT\"] /= np.mean(I_weights**2)\n",
    "# P_norm = np.mean(P_weights**2)\n",
    "# cl[\"EE\"] /= P_norm\n",
    "# cl[\"BB\"] /= P_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maps are smoothed (with different beams in different regions), so we try to select the region of $\\ell$ which is roughtly linear in `loglog` scale just before the curvature of the smoothing looks to start dominating. We will use this region to fit to extrapolate small scale power to high $\\ell$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(ell, A, gamma):\n",
    "    out = A * ell ** gamma\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pol=\"TT\"\n",
    "ell = np.arange(2049)\n",
    "plt.plot(ell, hp.gauss_beam(fwhm=np.radians(8/60 if pol == \"TT\" else 60), lmax=ell[-1])**2, label=\"Reference beam\")\n",
    "pol = \"EE\"\n",
    "plt.loglog(ell, hp.gauss_beam(fwhm=np.radians(8/60 if pol == \"TT\" else 1), lmax=ell[-1])**2, label=\"Reference beam\")\n",
    "plt.ylim(1e-10, 0)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sky = planck_mask.sum()/len(planck_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell_fit_low = {\"TT\":400, \"EE\":30, \"BB\":30}\n",
    "ell_fit_high = {\"TT\":600, \"EE\":110, \"BB\":110}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_fit, gamma_fit, A_fit_std, gamma_fit_std = {},{},{},{}\n",
    "for pol in spectra_components:\n",
    "    cosmic_variance = np.sqrt(2/((2*ell+1)*f_sky))*cl[pol]\n",
    "    xdata = np.arange(ell_fit_low[pol], ell_fit_high[pol])\n",
    "    cl_norm_fit = xdata*(xdata+1)/np.pi/2\n",
    "    ydata = np.fabs( cl_norm_fit * cl[pol][xdata])\n",
    "    (A_fit[pol], gamma_fit[pol]), cov = curve_fit(model, xdata, ydata, sigma=cl_norm_fit*cosmic_variance[xdata])\n",
    "\n",
    "    A_fit_std[pol], gamma_fit_std[pol] = np.sqrt(np.diag(cov))\n",
    "    plt.figure()\n",
    "    cl_norm =  ell*(ell+1)/np.pi/2 \n",
    "    plt.loglog(ell, cl_norm * cl[pol], label=\"NaMaster $C_\\ell$\")\n",
    "    # plt.semilogx(ell, ell*(ell+1)/np.pi/2 * cl[pol], label=\"NaMaster $C_\\ell smoothed$\")\n",
    "    # plt.loglog(ell, ell*(ell+1)/np.pi/2 * cl_sigma_G[pol], label=\"SS $C_\\ell$\")\n",
    "\n",
    "    plt.plot(ell[ell_fit_low[pol]//2:ell_fit_high[pol]*2], \n",
    "             model(ell[ell_fit_low[pol]//2:ell_fit_high[pol]*2], A_fit[pol], gamma_fit[pol]), label=\"model fit\")\n",
    "    \n",
    "    #plt.plot(w_ell**2,  label=f\"Beam {c} $C_\\ell$\")\n",
    "    plt.plot(ell, 6e-4 * hp.gauss_beam(fwhm=np.radians(8/60 if pol == \"TT\" else 1), lmax=ell[-1])**2, label=\"Reference beam\")\n",
    "\n",
    "    plt.axvline(ell_fit_low[pol], linestyle=\"--\", color=\"black\", label=\"$ \\ell={} $\".format(ell_fit_low[pol]))\n",
    "    plt.axvline(ell_fit_high[pol], linestyle=\"--\", color=\"gray\", label=\"$ \\ell={} $\".format(ell_fit_high[pol]))\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.title(f\"{pol} power spectrum for dust\")\n",
    "    plt.ylabel(\"$\\ell(\\ell+1)C_\\ell/2\\pi [\\mu K_{RJ}]$\")\n",
    "    plt.xlabel((\"$\\ell$\"))\n",
    "    #plt.xlim(0, 400)\n",
    "    #plt.ylim(1, 30);\n",
    "    plt.xlim(ell_fit_low[pol]//2, lmax)\n",
    "    plt.ylim(1e-5, 1e-1 if pol == \"TT\" else 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_fit, A_fit_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_fit, gamma_fit_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition\n",
    "\n",
    "Instead of clipping the measured spectra at some $\\ell$ and stitching the small scale extrapolation, I use a sigmoid function to make a sharp transition between the 2 curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from log_pol_tens_utils import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, x0, width, power=8):\n",
    "      \"\"\"Sigmoid function given start point and width\n",
    "  \n",
    "      Parameters\n",
    "      ----------\n",
    "      x : array\n",
    "          input x axis\n",
    "      x0 : float\n",
    "          value of x where the sigmoid starts (not the center)\n",
    "      width : float\n",
    "          width of the transition region in unit of x\n",
    "      power : float\n",
    "          tweak the steepness of the curve\n",
    "  \n",
    "      Returns\n",
    "      -------\n",
    "      sigmoid : array\n",
    "          sigmoid, same length of x\"\"\"\n",
    "        \n",
    "      return 1.0 / (1 + np.exp(-power * (x - x0) / width)) \n",
    "      #fwhm = 20 * u.arcmin\n",
    "      #return 1 - hp.gauss_beam(fwhm=fwhm.to_value(u.radian), lmax=x[-1])**2\n",
    "      #return np.heaviside(x - x0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pol in [\"TT\", \"EE\"]:\n",
    "    plt.figure()\n",
    "    plt.loglog(sigmoid(ell, ell_fit_high[pol], ell_fit_high[pol]/10), label=\"sigmoid\")\n",
    "    plt.plot(1-sigmoid(ell, ell_fit_high[pol], ell_fit_high[pol]/10), label=\"1-sigmoid\")\n",
    "    plt.plot(np.sqrt(1-sigmoid(ell, ell_fit_high[pol], ell_fit_high[pol]/10)), label=\"sqrt 1-sigmoid\")\n",
    "    plt.axvline(ell_fit_high[pol], color=\"black\", label=f\"$\\ell={ell_fit_high[pol]}$\")\n",
    "    plt.axvline(ell_fit_high[pol] + ell_fit_high[pol]/10, color=\"gray\", label=f\"$\\ell={ell_fit_high[pol]+ ell_fit_high[pol]//10}$\")\n",
    "    plt.ylim(1e-5, 2)\n",
    "    plt.grid()\n",
    "    plt.legend();\n",
    "    plt.title(f\"Sigmoid {pol}\")\n",
    "    plt.xlim(ell_fit_low[pol], ell_fit_high[pol]*1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate a realization of small scales fluctuations\n",
    "\n",
    "We simulate small scales fluctuations using the inverse of the window function and the fitted amplitude and slope.\n",
    "Also fix the seed to make this reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros(len(ell), dtype=np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_nside = 8192\n",
    "output_lmax = output_nside * 2\n",
    "output_ell = np.arange(output_lmax+1)\n",
    "output_cl_norm = output_ell * (output_ell+1) / 2 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_scales_input_cl = [\n",
    "#   np.heaviside(output_ell - ell_fit_low[pol]/2, 1) * model(output_ell, A_fit[pol], gamma_fit[pol]) * sigmoid(output_ell, ell_fit_high[pol], ell_fit_high[pol]/10) / output_cl_norm for pol in spectra_components\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_scales_input_cl = np.array([\n",
    "   model(output_ell, A_fit[pol], gamma_fit[pol]) * sigmoid(output_ell, ell_fit_high[pol], ell_fit_high[pol]/10) / output_cl_norm for pol in spectra_components\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_scales_input_cl[:, 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isnan(small_scales_input_cl).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isinf(small_scales_input_cl).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.write_cl(\"data/cl_dust_log_pol_tens_small_scales_neworder.fits\", small_scales_input_cl, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_scales_input_cl = np.array([\n",
    "    #np.heaviside(ell - ell_fit_low[pol]/2, 1)  \\\n",
    "    1 \\\n",
    "    * model(ell, A_fit[pol], gamma_fit[pol]) \\\n",
    "    * sigmoid(ell, ell_fit_high[pol], ell_fit_high[pol]/10)  \\\n",
    "    / cl_norm \\\n",
    "    for pol in spectra_components\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_scales_input_cl[:, 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sigma_G = hp.synfast(np.vstack([small_scales_input_cl, [zeros, zeros, zeros]]), nside, new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_m_sigma_G = hp.anafast(m_sigma_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(m_sigma_G[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(m_sigma_G[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cl = hp.anafast(m_sigma_G, lmax=lmax, use_pixel_weights=True)\n",
    "pol = \"TT\"\n",
    "plt.loglog(temp_cl[0]*cl_norm)\n",
    "plt.loglog(small_scales_input_cl[0]*cl_norm)\n",
    "plt.loglog(model(ell, A_fit[pol], gamma_fit[pol]))\n",
    "plt.grid();\n",
    "#del temp_cl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove small scales from the input maps\n",
    "\n",
    "Recover the full sky map and add back the monopole and dipole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alm_log_pol_tens_fullsky = hp.map2alm(log_pol_tens.data, lmax=lmax, use_pixel_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(log_pol_tens[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol=\"TT\"\n",
    "hp.almxfl(alm_log_pol_tens_fullsky[0],np.sqrt(1-sigmoid(ell, ell_fit_high[pol], ell_fit_high[pol]/10)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = \"EE\"\n",
    "sigmoid_pol = np.sqrt(1-sigmoid(ell, ell_fit_high[pol], ell_fit_high[pol]/10))\n",
    "for i in [1,2]:\n",
    "    hp.almxfl(alm_log_pol_tens_fullsky[i], sigmoid_pol, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.write_alm(\"data/alm_dust_log_pol_tens_large_scales.fits\", alm_log_pol_tens_fullsky, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pol_tens_largescales = hp.alm2map(alm_log_pol_tens_fullsky, nside=nside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine input maps without small scales to the simulated gaussian fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_log_pol_tens_map = log_pol_tens_largescales + m_sigma_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(m_sigma_G[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_map = log_pol_tens_to_map(output_log_pol_tens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.write_map(f\"data/gnilc_plus_smallscales_{comp}_nside{nside}.fits\", output_map, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute spectrum of the large scale map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pol_tens_largescales = hp.ma(log_pol_tens_largescales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pol_tens_largescales.mask = planck_mask < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono, dip = hp.fit_dipole(log_pol_tens_largescales[0])\n",
    "\n",
    "remove_dip_inplace(log_pol_tens_largescales[0], dip)\n",
    "log_pol_tens_largescales[0].data[:] -= mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(log_pol_tens_largescales[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(log_pol_tens_largescales.data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(log_pol_tens[1] - log_pol_tens_largescales[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell, cl_norm, cl_log_pol_tens_largescales = run_namaster(log_pol_tens_largescales.data, planck_mask, lmax=lmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import run_namaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_log_pol_tens_map = hp.ma(output_log_pol_tens_map)\n",
    "output_log_pol_tens_map.mask = planck_mask < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(output_log_pol_tens_map[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono, dip = hp.fit_dipole(output_log_pol_tens_map[0])\n",
    "\n",
    "remove_dip_inplace(output_log_pol_tens_map[0], dip)\n",
    "output_log_pol_tens_map[0].data[:] -= mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_log_pol_tens_map[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, cl_output_log_pol_tens = run_namaster(output_log_pol_tens_map.data, planck_mask, lmax=lmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, namaster_small_scales_cl = run_namaster(m_sigma_G, planck_mask, lmax=lmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_scales_cl = hp.anafast(m_sigma_G[0], lmax=lmax, use_pixel_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_fit, gamma_fit, A_fit_std, gamma_fit_std = {},{},{},{}\n",
    "for i_pol, pol in enumerate(spectra_components):\n",
    "    xdata = np.arange(ell_fit_low[pol], ell_fit_high[pol])\n",
    "    ydata = xdata*(xdata+1)/np.pi/2 * cl[pol][xdata]\n",
    "    (A_fit[pol], gamma_fit[pol]), cov = curve_fit(model, xdata, ydata)\n",
    "\n",
    "    A_fit_std[pol], gamma_fit_std[pol] = np.sqrt(np.diag(cov))\n",
    "    plt.figure()\n",
    "    plt.loglog(ell, cl_norm * cl[pol], label=\"NaMaster $C_\\ell$\")\n",
    "    plt.loglog(ell, cl_norm * cl_output_log_pol_tens[pol][:len(ell)], label=\"Output $C_\\ell$\")\n",
    "    # plt.loglog(ell, cl_norm * small_scales_cl, label=\"small scales $C_\\ell$\")\n",
    "    #plt.loglog(ell, cl_norm * namaster_small_scales_cl[\"II\"], label=\"small scales $C_\\ell$\")\n",
    "\n",
    "    plt.plot(ell[ell_fit_low[pol]//2:ell_fit_high[pol]*2], \n",
    "             model(ell[ell_fit_low[pol]//2:ell_fit_high[pol]*2], A_fit[pol], gamma_fit[pol]), label=\"model fit\")\n",
    "    \n",
    "    plt.plot(small_scales_input_cl[i_pol]*cl_norm, label=\"Small scales $C_\\ell$\")\n",
    "    #plt.plot(cl_log_pol_tens_largescales[pol]*cl_norm, label=\"Large scales $C_\\ell$\")\n",
    "    \n",
    "    plt.axvline(ell_fit_low[pol], linestyle=\"--\", color=\"black\", label=\"$ \\ell={} $\".format(ell_fit_low[pol]))\n",
    "    plt.axvline(ell_fit_high[pol], linestyle=\"--\", color=\"gray\", label=\"$ \\ell={} $\".format(ell_fit_high[pol]))\n",
    "    #plt.loglog(1e-6*(1-sigmoid(ell, ell_fit_high[pol], ell_fit_high[pol]/10))*cl_norm, label=\"1-sigmoid\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.title(f\"{pol} power spectrum for dust\")\n",
    "    plt.ylabel(\"$\\ell(\\ell+1)C_\\ell/2\\pi [\\mu K_{RJ}]$\")\n",
    "    plt.xlabel((\"$\\ell$\"))\n",
    "    #plt.xlim(0, 400)\n",
    "    #plt.ylim(1, 30);\n",
    "    plt.xlim(ell_fit_low[pol]*.9, lmax)\n",
    "    plt.ylim(1e-5 if pol == \"TT\" else 1e-6, 1e-2 if pol == \"TT\" else 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "namaster",
   "language": "python",
   "name": "namaster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
